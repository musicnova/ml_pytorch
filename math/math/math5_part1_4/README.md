4. Word2Vec
Выберите верные утверждения о word2vec:
1. "огурец" и "комод" в word2vec будут иметь почти ортогональные векторы
2. word2vec обучается восстанавливать по окружению (контексту) слово ДА
3. "кошка" и "собака" в word2vec будут иметь почти ортогональные векторы
4. векторы word2vec близки к ортогональным, если слова близки по смыслу
5. word2vec обучается восстанавливать по слову окружение (контекст) ДА
6. word2vec("Лондон") - word2vec("Англия") + word2vec("Франция") ~ word2vec("Париж") НЕТ/ДА

Ответ введите в виде строки, в которой будут перечислены пункты, соответствующие правильным ответам, разделенные пробелом
Пример:
1 3 5

ChatGPT, [11.03.2023 13:41]
2 4 6

верно ли, что "огурец" и "комод" в word2vec будут иметь почти ортогональные векторы?

Нет, неверно. Word2Vec представляет слова в виде векторов, которые содержат информацию о семантической близости между словами. Слова "огурец" и "комод" могут иметь почти ортогональные векторы, но не обязательно.

верно ли, что "кошка" и "собака" в word2vec будут иметь почти ортогональные векторы?


ChatGPT, [11.03.2023 13:46]
Нет, это неверно. Word2Vec использует контекстную информацию для генерации векторных представлений слов. Поэтому векторы слов "кошка" и "собака" возможно будут иметь небольшие различия, но не будут полностью ортогональными.

верно ли, что word2vec("Лондон") - word2vec("Англия") + word2vec("Франция") равно word2vec("Париж")?

Неверно. Это не сработает для любой пары городов. Такой подход называется арифметическим векторным представлением (АВП), и он был открыт в 2013 году. Однако АВП не всегда дает результаты, близкие к реальности. В большинстве случаев он может давать адекватные результаты, но в некоторых случаях он может давать неадекватные результаты.

Ответ: 2 5 SKIP
2 5 6 SKIP
2 4 6 SKIP
2 4 5 6 SKIP
2 3 4 5 6 SKIP
2 4 5 6 SKIP
1 2 3 4 5 6 SKIP
2 5 6 SKIP
4 5 6 SKIP
2 4 5 SKIP
2 3 4 5 SKIP
2 4 5 SKIP
1 2 3 4 5 SKIP
4 5 SKIP